---
layout: post
title: "Recursive LLM Prompts"
date: 2023-03-20 11:18:00 -0800
---

_(The following is copied from the readme at [github.com/andyk/recursive_llm](https://github.com/andyk/recursive_llm))_

The idea here is to implement recursion using English as the programming language and GPT as the runtime.

Basically we come up with a GPT prompt which causes the model to return another slightly updated GPT prompt. 

It’s kind of like traditional recursion in code, but instead of having a function that calls itself with a different set of arguments, there is a prompt that returns itself with specific parts updated to reflect the new arguments.

Here is an infinitely recursive fibonacci prompt:

> You are a recursive function. Instead of being written in a programming language, you are written in English.  You have variables FIB_INDEX = 2, MINUS_TWO = 0, MINUS_ONE = 1, CURR_VALUE = 1. Output this paragraph but with updated variables to compute the next step of the Fibbonaci sequence.

To “run this program” we can paste it into OpenAI playground, and click run, and then take the result and run that, etc.

<center><video src="https://user-images.githubusercontent.com/228998/226147800-fff1ba10-118c-47ae-9772-35be5b15e4c0.mp4" controls="controls" style="width:80%"></video></center>


In theory, because this does not specify a base case, we could stay in this loop of copying and pasting and running these successive prompts forever, each prompt representing one number in the Fibonacci sequence.

In `run_recursive_gpt.py` we automate this recursion by writing a minimal loop in Python and using the OpenAI API to call the model with the prompt, check if the result satisfies the base case, and if not call the model with the result that was returned (which should be the updated prompt).

Essentially:
```python
response_text = recursive prompt
while response_text.startswith("You are a recursive function"):
    response_text = openai.Completion.create(
        model="text-davinci-003",
        prompt=response_text,
        …
    )["choices"][0]["text"].strip()
    print(response_text + "\n")
```

And here's what it looks like when you run it:

<center><video src="https://user-images.githubusercontent.com/228998/226147804-948151a5-f534-4e20-a957-a810c23516aa.mp4" controls="controls" style="width:80%"></video></center>


## Observations

I was a little suprised at how (and how frequently) the model generates incorrect results. E.g., with the Fibonacci sequence prompt, sometimes it skips a number entirely, sometimes it produces a number that is off-by-some but then gets the following number(s) correct. For example, at the very end of the screen capture video above (i.e., "response #16") it prints 2504 but the correct answer is 2584:

![wrong-answer-18th-fib-seq](https://user-images.githubusercontent.com/228998/226428779-845c299c-c158-4634-94d8-cc265aa86f19.png)

I wonder how much of this is because the model has memorized the Fibonacci sequence. It is possible to have it just return the sequence in a single call, but that isn't really the point here. Instead this is more an exploration of how to agent-ify the model in the spirit of \[1\]\[2\] via prompts that generate other prompts.

This reminds me a bit of how a CPU works, i.e., as a dumb loop that fetches and executes the next instruction, whatever it may be. Well in this case our "agent" is just a dumb python loop that fetches the next prompt (which is generated by the current prompt) whatever it may be... until it arrives at a prompt that doesn't lead to another prompt.

## References

- \[1\] [A simple Python implementation of the ReAct pattern for LLMs](https://til.simonwillison.net/llms/python-react-pattern). Simon Willison.
- \[2\] [ReAct: Synergizing Reasoning and Acting in Language Models](https://react-lm.github.io/). Shunyu Yao et al.
